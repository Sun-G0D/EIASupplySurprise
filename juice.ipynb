{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebf52349-3294-4698-b783-ba72e43ff06d",
   "metadata": {},
   "source": [
    "# Supply and Demand Principles Outside of an Introductory Economics Course: An Investigation of the Energy Information Administration's(EIA) Weekly Petroleum Status Report(WPSR) and Crude Oil Futures\n",
    "\n",
    "This project aims to analyze the impact of unexpected changes in crude oil supply, as reported by the EIA WPSR, on the price of crude oil. By comparing historical EIA WPSR data and 3rd-party supply estimates alongside minute-resolution crude oil price data, the analysis investigates the market's reaction to these supply \"surprises.\" \n",
    "\n",
    "## Research Question 1. How might one characterize the effect that the EIA WPSR release have on the Crude Oil Futures Market? Is it statistically significant and over what time interval is this effect the strongest?\n",
    "\n",
    "##### Yes, we conclude that the release of the WPSR definitely affects the Crude Oil Futures market based on 2 main findings:\n",
    "##### Finding #1: In the minutes before(~30 min) the release of the EIA WPSR, trading volume steadily drops before sharply jumping exactly when the report is released.\n",
    "This suggests that before the release, traders are wary of the price change that will result from the report and thus resulting in less trading activity. Then at the moment of release, the information is absorbed by the market leading to a significant jump in activity as traders seek to capitalize on the subsequent price change.\n",
    "##### Finding #2: Once the report is released, minute-to-minute price behavior is different in a statistically different way for around 3 minutes.\n",
    "In comparing post-release price activity to relevant \"normal\" price behavior, it's especially apparent (even visually) that price seems to be much more likely to move when a report is released compared to days when there is no report.\n",
    "Additionally, when conducting a two-sample Kolmogorov-Smirnov test on the minute-to-minute price change distributions after WPSR releases, the p-value stays below the chosen threshould (<0.1) until the end of the 3rd minute after the report is released. Thus it is likely that it takes around 2 minutes before the market fully absorbs the new information of the WPSR release and resumes \"regular\" trading behavior.\n",
    "\n",
    "## Research Question 2. Among the new market-relevant information found in the the EIA WPSR, what portion/s of the data is most relevant to the traders, and thus most relevant to the \"irregular\" price behavior?\n",
    "\n",
    "##### Based on the findings of Research Question #1 we now looked to figure out *how* the WPSR was causing a change in market behavior. In our research we initially hypothesized traders would fall into two main interpretations of the EIA WPSR information, all fundamentally based on simple microeconomic supply and demand principles; an excess supply imbalance would result in price decreases and an excess demand imbalance would result in price increases.\n",
    "##### Interpretation #1: Traders are taking the raw week-to-week change in Crude Oil supply as the best reflection of market supply and demand imbalance.\n",
    "This would mean that the price behavior should be somewhat linearly correlated with domestic crude oil supply changes, i.e increasingly positive weekly supply changes lead to similarly significant price decreases and vice versa.\n",
    "##### Interpretation #2: Traders are taking the difference between EIA's supply change estimate and 3rd party supply change predictions(Investing.com or American Petroleum Institute) as the best reflection of market supply and demand imbalance.\n",
    "This interpretation builds on the first one, in that it essentially assumes the market price always reflects some consensus on the running supply change and that each release of the WPSR acts as a sort of correction. \n",
    "##### After looking deeper into the data with visualizations and regression tests we found the relationship between supply-demand imbalances and price movement to be heavily obscured by noise and that the relationship. At this point we also realized the relationship didn't seem very linearly correlated as we had hoped. Ultimately, we decided to move forward with Interpretation #1 as it seemed to result in the least noise upon visual inspection.\n",
    "\n",
    "\n",
    "## Research Question 3. Given the noise and possible non-linearity found in the relationship between the WPSR supply change information and the crude oil futures price movement, how can we use machine learning techniques to model this relationship and predict the price behavior based on the information found in the WPSR?\n",
    "\n",
    "##### All in all, we compared a total of 6 different types of machine learning models to try and capture possible non-linear patterns in the data. Unfortunately, out of OLS Linear Regression, Kernel Regression(Gaussian Kernel), LOESS Regression, Random Forest Regression, Random Forest Regression + Gradient Boosting(XGBoost), and Ridge Regression we weren't able to produce any significantly accurate models, with our best model being a Random Forest Regressor which achieved an R-squared value of 0.0171 and a Mean Squared Error of 0.0290. \n",
    "##### After careful consideration of the impending deadline and the class this project was meant for, we concluded that the exact mechanisms behind the erratic price behavior upon the EIA's WPSR release likely lay beyond the scope of our knowledge and expertise. Thus, while it is definitely possible and even likely that the WPSR affects crude oil futures prices, the relationship between the two is likely much more complex than the supply and demand principles that can be found in an introductory Microeconomics textbook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e331f5-20f9-442c-ab65-364d4efb118c",
   "metadata": {},
   "source": [
    "## Challenge Goals\n",
    "\n",
    "#### Multiple Datasets: \n",
    "This project meets the Multiple Datasets challenge goal since it \n",
    "utilizes 3 distinct datasets: \n",
    "- Energy Information Administration's Weekly Petroleum Status Report\n",
    "- American Petroleum Institute's Weekly Statistical Bulletin\n",
    "- West Texas Intermediate Crude Oil Futures Contracts\n",
    "  \n",
    "Additionally, all of our research questions rely on using at least 2 and sometimes multiple datasets for their answer. Lastly, we fulfill the last requirement of this challenge goal since we merge multiple datasets throughout the project such as when we are creating the price windows for EIA WPSR release days.\n",
    "Additionally\n",
    "#### New Library: \n",
    "This project meets the New Library challenge goal since it utilizes a multitude of new libraries not covered in the class such as plotly, scipy, statsmodels, and xgboost.\n",
    "#### Advanced Machine Learning:\n",
    "This project meets the Advanced Machine Learning challenge goal in two ways:\n",
    "- We applied a gradient boosting technique to a Random Forest Regressor model called XGBoost which isn't included in the scikit-learn library.\n",
    "- We also compare 5 different machine learning algorithms on various statistics such as MSE and $R^2$ with hyperparameter optimization done using GridSearchCV."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc3ea93-fc61-402a-bf04-490729b600d8",
   "metadata": {},
   "source": [
    "## Collaboration and Conduct\n",
    "\n",
    "Students are expected to follow Washington state law on the [Student Conduct Code for the University of Washington](https://www.washington.edu/admin/rules/policies/WAC/478-121TOC.html). In this course, students must:\n",
    "\n",
    "- Indicate on your submission any assistance received, including materials distributed in this course.\n",
    "- Not receive, generate, or otherwise acquire any substantial portion or walkthrough to an assessment.\n",
    "- Not aid, assist, attempt, or tolerate prohibited academic conduct in others.\n",
    "\n",
    "Update the following code cell to include your name and list your sources. If you used any kind of computer technology to help prepare your assessment submission, include the queries and/or prompts. Submitted work that is not consistent with sources may be subject to the student conduct process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c5d696-2e15-4c25-9fdf-b31e535b9c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import pytz\n",
    "import plotly.graph_objects as go\n",
    "from plotly.offline import iplot\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import plotly.io as pio\n",
    "\n",
    "\n",
    "your_name = \"Evan Sun, Ruifeng Tian, and Aaron Shayne Jacowitz\"\n",
    "sources = [\n",
    "    \"EIA weekly crude oil supply (Google Search) -> https://www.eia.gov/petroleum/supply/weekly/pdf/wpsrall.pdf\",\n",
    "    \"crude oil futures contract intraday historical data (Google Search) -> https://www.backtestmarket.com/en/historical-data/commodities/crude-oil\",\n",
    "    \"est.localize (Google Search) -> https://stackoverflow.com/questions/15641898/python-timezone-localize-not-working\",\n",
    "    \"b in datetime python (Google Search) -> https://stackoverflow.com/questions/61699115/b-vs-b-in-datetime-module-python-3\",\n",
    "    \".to_datetime errors coerce (Google Search) -> https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html\",\n",
    "    \".apply pandas (Google Search) -> https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.apply.html\",\n",
    "    \"check for nan values in pandas (LLM Prompt)\",\n",
    "    \"install plotly (Google Search) -> https://pypi.org/project/plotly/\",\n",
    "    \"what is -m option in python pip (LLM Prompt)\",\n",
    "    \"Crude oil inventories EIA (Google Search) -> https://www.investing.com/economic-calendar/eia-crude-oil-inventories-75\",\n",
    "    \"how to hide a python cell but keep output in jupyter notebook (Google Search) -> https://jupyterbook.org/en/stable/interactive/hiding.html\"\n",
    "]\n",
    "\n",
    "assert your_name != \"\", \"your_name cannot be empty\"\n",
    "assert ... not in sources, \"sources should not include the placeholder ellipsis\"\n",
    "assert len(sources) >= 6, \"must include at least 6 sources, inclusive of lectures and sections\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "aafe0be3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "iframe {\n",
       "  margin:auto;\n",
       "  display:block;\n",
       "  width: 80%;\n",
       "  aspect-ratio: 3 / 1;\n",
       "}\n",
       "\n",
       "img {\n",
       "  margin:auto;\n",
       "  display:block;\n",
       "  width: 80%;\n",
       "  aspect-ratio: 16 / 9;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "iframe {\n",
    "  margin:auto;\n",
    "  display:block;\n",
    "  width: 80%;\n",
    "  aspect-ratio: 3 / 1;\n",
    "}\n",
    "\n",
    "img {\n",
    "  margin:auto;\n",
    "  display:block;\n",
    "  width: 80%;\n",
    "  aspect-ratio: 16 / 9;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a9116b-b1c6-424a-a790-037dd3a8a55b",
   "metadata": {},
   "source": [
    "## Data Setting and Methods\n",
    "\n",
    "**1. Data Setting**\n",
    "\n",
    "The analysis utilizes three primary datasets:\n",
    "\n",
    "*   **EIA WPSR Forecast Data (icom_eia_forecasts):** This dataset comprises historical records of EIA WPSR releases, including:\n",
    "    *   **Release Date and Time:**  The date and time of the EIA report release. The time zone of this data is EST\n",
    "    *   **Actual Change in Crude Oil Inventories:** The officially reported change in U.S. commercial crude oil inventories (in millions of barrels).\n",
    "    *   **Market Forecasts:**  Pre-release consensus forecasts for the change in crude oil inventories (in millions of barrels), sourced from a third-party provider.\n",
    "    *   **Previous Period's Actual:** The actual inventory change from the preceding reporting period.\n",
    "    *   The dataset is provided in a tabular format with date and time components spread across 'Release Date' and 'Time' columns, with inventory figures often suffixed with 'M' to denote millions.\n",
    "\n",
    "\n",
    "*   **Minute-Resolution WTI Crude Oil Price Data (min_WTI):** This dataset provides high-frequency, minute-by-minute price and volume data for WTI crude oil futures.  Key variables include:\n",
    "    *   **Date and Time:**  The date and time of each minute bar.\n",
    "    *   **Open, High, Low, Close (OHLC) Prices:**  The open, high, low, and closing prices for each minute interval.\n",
    "    *   **Volume:**  The trading volume within each minute interval.\n",
    "    *   The dataset is structured with 'Date' and 'Time' columns, requiring combination to create a unified datetime index.  The time zone of this data is specified as GMT-6 or CST.\n",
    "\n",
    "*   **API WSB Data (fxstreet_api_forecasts):** This dataset provides historical records of API WSB releases, including:\n",
    "    *   **Date (Reference):**  The date on which the entry was released with the week of reference in parentheses.\n",
    "    *   **Actual:**  The estimated change in U.S. commerical crude oil inventories as estimated by the American Petroleum Institute.\n",
    "    *   **Deviation:**  A supply surprise statistic calculated by a third-party (FXStreet).\n",
    "    *   **Consensus:** An \"agreed\" upon prediction by Wall Street on the week's supply change.\n",
    "\n",
    "**2. Data Transformations**\n",
    "\n",
    "*   **Datetime Standardization:**  Both datasets required standardization of their date and time formats to enable accurate time-based merging and analysis.\n",
    "    After standardization, the 'Release_Datetime' column in `icom_eia_forecasts` and a new 'Datetime' column in `min_WTI` were set as the index for their respective dataframes to facilitate time-based data retrieval and merging.  Timezone considerations were addressed by converting all datetimes to Eastern Standard Time (EST) to ensure consistency.\n",
    "\n",
    "*   **Supply Surprise Calculation:**  To quantify the unexpected component of EIA releases, a 'supply\\_surprise' column was calculated in the `icom_eia_forecasts` dataframe using the `calculate_supply_surprise(df)` function. This function computes the difference between the 'Actual' and 'Forecast' inventory change values.  It also handles the 'M' suffix in the inventory figures, converting them to numeric values (in millions of barrels) before calculating the difference.\n",
    "\n",
    "*   **Price Window Extraction:** To analyze the intraday price reaction around EIA releases, the `get_price_windows(eia_release_times, price_data, window_minutes_before=60, window_minutes_after=60)` function was utilized. This function extracts minute-resolution price data from `min_WTI` for a specified window period (e.g., 60 minutes before and 60 minutes after) each EIA report release time.  The function iterates through each release time in `icom_eia_forecasts`, retrieves the corresponding price window from `min_WTI` based on the datetime index, and concatenates these windows into a new dataframe (`price_window_60min`) for event study analysis.\n",
    "\n",
    "\n",
    "**3. Methods**\n",
    "\n",
    "To address the research questions regarding the market impact of EIA WPSR supply surprises, the following analytical methods are employed:\n",
    "\n",
    "*   **Event Study Methodology:** An event study approach is used to examine the short-term impact of EIA WPSR releases on WTI crude oil prices.  The 'event' is defined as the EIA WPSR report release. Price changes are measured over various time intervals *relative to* the release time (e.g., 1 minute after, 2 minutes after, etc)\n",
    "\n",
    "*   **Percentage Price Change Calculation:** To standardize price reaction comparisons across different release events and price levels, percentage price changes are calculated.  For each EIA release, the percentage price change is computed as: ((Price at Time t+ $\\Delta t$ - Price at Time t) / Price at Time t) * 100%, where Time t is the release time and $\\Delta t$ represents the time interval (e.g., 1 minute, 5 minutes).\n",
    "\n",
    "\n",
    "*   **Visualizations:**  Interactive visualizations are generated to explore the data and results:\n",
    "    *   **Histograms:** Histograms are created to visualize the distribution of supply surprises and the distributions of percentage price changes for each time interval. This helps assess the shape and characteristics of these distributions, including normality.\n",
    "    *   **Scatter Plots:** Scatter plots are used to examine the average trading volume around EIA release times, illustrating intraday volume patterns and potential volume spikes associated with releases.\n",
    "\n",
    "*   **Kolmogorov-Smirnov Test:** To formally test for the EIA WPSR associated price change distributions, a two-sample Kolmogorov-Smirnov (KS) test is applied. This non-parametric test compares the empirical cumulative distribution function of the post-release price changes on days of release to post-release price changes on days without a report, providing a statistical measure of the difference in market behavior and a p-value to assess the significance of any deviations from normality.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33cecd7f-eb42-4ef6-bde8-d1283ceb792a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_eia_datetime(row):\n",
    "    \"\"\"Standardizes datetime for EIA forecast\"\"\"\n",
    "    release_date = pd.to_datetime(row['Release Date'], format='%d-%b-%y', errors='coerce').date()\n",
    "    release_time = pd.to_datetime(row['Time'], format='%H:%M', errors='coerce').time()\n",
    "\n",
    "    if pd.isna(release_date) or pd.isna(release_time):\n",
    "        print('nan')\n",
    "        return pd.NaT\n",
    "\n",
    "    combined_datetime = pd.Timestamp.combine(release_date, release_time)\n",
    "    return combined_datetime\n",
    "\n",
    "test_cases = [\n",
    "    {\n",
    "        'input': {'Release Date': '01-Jan-23', 'Time': '09:00'},\n",
    "        'expected': pd.Timestamp('2023-01-01 09:00:00')\n",
    "    },\n",
    "    {\n",
    "        'input': {'Release Date': '15-Dec-22', 'Time': '14:30'},\n",
    "        'expected': pd.Timestamp('2022-12-15 14:30:00')\n",
    "    },\n",
    "    {\n",
    "        'input': {'Release Date': '31-Dec-22', 'Time': '23:59'},\n",
    "        'expected': pd.Timestamp('2022-12-31 23:59:00')\n",
    "    },\n",
    "    {\n",
    "        'input': {'Release Date': '01-Apr-23', 'Time': '00:00'},\n",
    "        'expected': pd.Timestamp('2023-04-01 00:00:00')\n",
    "    }\n",
    "]\n",
    "\n",
    "def test_standardize_eia_datetime():\n",
    "    for i, test_case in enumerate(test_cases):\n",
    "        input_row = test_case['input']\n",
    "        expected_output = test_case['expected']\n",
    "\n",
    "        try:\n",
    "            actual_output = standardize_eia_datetime(input_row)\n",
    "            assert actual_output == expected_output, f\"Test case {i+1} failed: expected {expected_output}, got {actual_output}\"\n",
    "        except AssertionError as e:\n",
    "            print(e)\n",
    "        except Exception as e:\n",
    "            print(f\"Test case {i+1} failed with an unexpected error: {e}\")\n",
    "\n",
    "test_standardize_eia_datetime()\n",
    "\n",
    "\n",
    "def standardize_wti_datetime(row):\n",
    "    \"\"\"Standardizes datetime for min_WTI dataframe.\"\"\"\n",
    "    date_str = row['Date']\n",
    "    time_str = row['Time']\n",
    "\n",
    "    combined_datetime = pd.to_datetime(date_str + ' ' + time_str, format='%d/%m/%Y %H:%M:%S', errors='coerce')\n",
    "\n",
    "    if pd.isna(combined_datetime):\n",
    "        print('nan')\n",
    "        return pd.NaT\n",
    "    return combined_datetime\n",
    "\n",
    "test_cases = [\n",
    "    {\n",
    "        'input': {'Date': '01/01/2023', 'Time': '09:00:00'},\n",
    "        'expected': pd.Timestamp('2023-01-01 09:00:00')\n",
    "    },\n",
    "    {\n",
    "        'input': {'Date': '15/12/2022', 'Time': '14:30:00'},\n",
    "        'expected': pd.Timestamp('2022-12-15 14:30:00')\n",
    "    },\n",
    "    {\n",
    "        'input': {'Date': '31/12/2022', 'Time': '23:59:59'},\n",
    "        'expected': pd.Timestamp('2022-12-31 23:59:59')\n",
    "    },\n",
    "    {\n",
    "        'input': {'Date': '01/04/2023', 'Time': '00:00:00'},\n",
    "        'expected': pd.Timestamp('2023-04-01 00:00:00')\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "def test_standardize_wti_datetime():\n",
    "    for i, test_case in enumerate(test_cases):\n",
    "        input_row = test_case['input']\n",
    "        expected_output = test_case['expected']\n",
    "\n",
    "        actual_output = standardize_wti_datetime(input_row)\n",
    "        try:\n",
    "            assert actual_output == expected_output, f\"Test case {i+1} failed: expected {expected_output}, got {actual_output}\"\n",
    "        except AssertionError as e:\n",
    "            print(e)\n",
    "\n",
    "test_standardize_wti_datetime()\n",
    "\n",
    "def calculate_supply_surprise(df):\n",
    "    \"\"\"\n",
    "    Calculates the 'supply_surprise' column as the difference between 'Actual' and 'Forecast'.\n",
    "    Handles 'M' suffix and converts to numeric.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): icom_eia_forecasts DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: Supply surprise values.\n",
    "    \"\"\"\n",
    "    actual = df['Actual'].str.replace('M', '', regex=False).astype(float)\n",
    "    forecast = df['Forecast'].str.replace('M', '', regex=False).astype(float)\n",
    "    supply_surprise = actual - forecast\n",
    "    return supply_surprise\n",
    "\n",
    "test_data = {\n",
    "    'Actual': ['10M', '20M', '15.5M', '10'],\n",
    "    'Forecast': ['8M', '22M', '14M', '5']\n",
    "}\n",
    "\n",
    "df_test = pd.DataFrame(test_data)\n",
    "\n",
    "expected_results = [2.0, -2.0, 1.5, 5.0, pd.NA, pd.NA]\n",
    "\n",
    "def test_calculate_supply_surprise():\n",
    "    result = calculate_supply_surprise(df_test)\n",
    "\n",
    "    for i, (actual, expected) in enumerate(zip(result, expected_results)):\n",
    "        if pd.isna(expected):\n",
    "            assert pd.isna(actual), f\"Test case {i+1} failed: expected NA, got {actual}\"\n",
    "        else:\n",
    "            try:\n",
    "                assert actual == expected, f\"Test case {i+1} failed: expected {expected}, got {actual}\"\n",
    "            except AssertionError as e:\n",
    "                print(e)\n",
    "\n",
    "test_calculate_supply_surprise()\n",
    "\n",
    "\n",
    "def get_price_windows(eia_release_times, price_data, window_minutes_before=60, window_minutes_after=60):\n",
    "    \"\"\"\n",
    "    Extracts price data windows around EIA report release times.\n",
    "\n",
    "    Args:\n",
    "        eia_release_times (pd.DatetimeIndex): Index of icom_eia_forecasts (release datetimes).\n",
    "        price_data (pd.DataFrame): min_res_OIH dataframe with Datetime index.\n",
    "        window_minutes_before (int): Minutes to include before release time.\n",
    "        window_minutes_after (int): Minutes to include after release time.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing price data for all events, within the specified windows.\n",
    "                      Returns an empty DataFrame if no data is found within any window.\n",
    "    \"\"\"\n",
    "    price_windows_list = []\n",
    "\n",
    "    for release_time in eia_release_times:\n",
    "        start_time = release_time - pd.Timedelta(minutes=window_minutes_before)\n",
    "\n",
    "        end_time = release_time + pd.Timedelta(minutes=window_minutes_after)\n",
    "\n",
    "        window_data = price_data.loc[start_time:end_time].copy()\n",
    "\n",
    "\n",
    "        if not window_data.empty:\n",
    "            window_data['Release_Datetime'] = release_time\n",
    "            price_windows_list.append(window_data)\n",
    "\n",
    "    if price_windows_list:\n",
    "        price_windows_df = pd.concat(price_windows_list)\n",
    "        return price_windows_df\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n",
    "eia_release_times = pd.DatetimeIndex([\n",
    "    '2023-01-01 09:00:00',\n",
    "    '2023-01-02 09:00:00',\n",
    "    '2023-01-03 09:00:00'\n",
    "])\n",
    "\n",
    "price_data = pd.DataFrame({\n",
    "    'Price': [100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111],\n",
    "}, index=pd.DatetimeIndex([\n",
    "    '2023-01-01 08:30:00',\n",
    "    '2023-01-01 09:00:00',\n",
    "    '2023-01-01 09:30:00',\n",
    "    '2023-01-01 10:00:00',\n",
    "    '2023-01-02 08:30:00',\n",
    "    '2023-01-02 09:00:00',\n",
    "    '2023-01-02 09:30:00',\n",
    "    '2023-01-02 10:00:00',\n",
    "    '2023-01-03 08:30:00',\n",
    "    '2023-01-03 09:00:00',\n",
    "    '2023-01-03 09:30:00',\n",
    "    '2023-01-03 10:00:00'\n",
    "]))\n",
    "\n",
    "expected_results = pd.DataFrame({\n",
    "    'Price': [100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111],\n",
    "    'Release_Datetime': [\n",
    "        '2023-01-01 09:00:00', '2023-01-01 09:00:00', '2023-01-01 09:00:00', '2023-01-01 09:00:00',\n",
    "        '2023-01-02 09:00:00', '2023-01-02 09:00:00', '2023-01-02 09:00:00', '2023-01-02 09:00:00',\n",
    "        '2023-01-03 09:00:00', '2023-01-03 09:00:00', '2023-01-03 09:00:00', '2023-01-03 09:00:00'\n",
    "    ]\n",
    "}, index=pd.DatetimeIndex([\n",
    "    '2023-01-01 08:30:00', '2023-01-01 09:00:00', '2023-01-01 09:30:00', '2023-01-01 10:00:00',\n",
    "    '2023-01-02 08:30:00', '2023-01-02 09:00:00', '2023-01-02 09:30:00', '2023-01-02 10:00:00',\n",
    "    '2023-01-03 08:30:00', '2023-01-03 09:00:00', '2023-01-03 09:30:00', '2023-01-03 10:00:00'\n",
    "]))\n",
    "\n",
    "expected_results['Release_Datetime'] = pd.to_datetime(expected_results['Release_Datetime'])\n",
    "\n",
    "def test_get_price_windows():\n",
    "    result = get_price_windows(eia_release_times, price_data, window_minutes_before=60, window_minutes_after=60)\n",
    "\n",
    "    try:\n",
    "        pd.testing.assert_frame_equal(result, expected_results, check_like=True)\n",
    "    except AssertionError as e:\n",
    "        print(\"Test failed:\")\n",
    "        print(e)\n",
    "\n",
    "test_get_price_windows()\n",
    "\n",
    "\n",
    "def time_difference(time1, time2):\n",
    "    \"\"\"\n",
    "    Calculates the time difference in seconds between two datetime.time objects.\n",
    "\n",
    "    Args:\n",
    "        time1: The first datetime.time object.\n",
    "        time2: The second datetime.time object.\n",
    "\n",
    "    Returns:\n",
    "        The time difference in minutes as a float.\n",
    "    \"\"\"\n",
    "    dummy_date = datetime.date(1, 1, 1)\n",
    "    datetime1 = datetime.datetime.combine(dummy_date, time1)\n",
    "    datetime2 = datetime.datetime.combine(dummy_date, time2)\n",
    "\n",
    "    time_delta = datetime2 - datetime1\n",
    "\n",
    "    return time_delta.total_seconds() / 60\n",
    "\n",
    "def test_time_difference():\n",
    "    time1 = datetime.time(12, 0, 0)\n",
    "    time2 = datetime.time(12, 0, 0)\n",
    "    assert abs(time_difference(time1, time2) - 0.0) < 1e-6, \"Test case 1 failed\"\n",
    "\n",
    "    time1 = datetime.time(12, 0, 0)\n",
    "    time2 = datetime.time(12, 1, 0)\n",
    "    assert abs(time_difference(time1, time2) - 1.0) < 1e-6, \"Test case 2 failed\"\n",
    "\n",
    "    time1 = datetime.time(12, 0, 0)\n",
    "    time2 = datetime.time(13, 0, 0)\n",
    "    assert abs(time_difference(time1, time2) - 60.0) < 1e-6, \"Test case 3 failed\"\n",
    "\n",
    "    time1 = datetime.time(13, 0, 0)\n",
    "    time2 = datetime.time(12, 0, 0)\n",
    "    assert abs(time_difference(time1, time2) + 60.0) < 1e-6, \"Test case 6 failed\"\n",
    "\n",
    "test_time_difference()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def format_fxstreet_date(date_str):\n",
    "    \"\"\"\n",
    "    Extracts the date part from the fxstreet date string and formats it as day/month/year.\n",
    "\n",
    "    Args:\n",
    "        date_str (str): The original date string from the 'Date' column.\n",
    "\n",
    "    Returns:\n",
    "        str: Formatted date string in day/month/year format (e.g., \"04/03/2025\").\n",
    "             Returns original string if formatting fails.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        date_part = date_str.split('(')[0].strip()\n",
    "        datetime_obj = pd.to_datetime(date_part, format='%m/%d/%Y')\n",
    "        formatted_date_str = datetime_obj.strftime('%d/%m/%Y')\n",
    "        return formatted_date_str\n",
    "    except Exception as e:\n",
    "        return date_str\n",
    "\n",
    "test_cases = [\n",
    "    (\"04/03/2025 (Wednesday)\", \"03/04/2025\"),\n",
    "    (\"12/31/2023 (Sunday)\", \"31/12/2023\"),\n",
    "    (\"01/01/2024 (Tuesday)\", \"01/01/2024\"),\n",
    "    (\"04/03/2025\", \"03/04/2025\"),\n",
    "    (\"13/13/2023 (Invalid)\", \"13/13/2023 (Invalid)\"),\n",
    "]\n",
    "\n",
    "def test_format_fxstreet_date():\n",
    "    for input_date, expected_output in test_cases:\n",
    "        actual_output = format_fxstreet_date(input_date)\n",
    "        assert actual_output == expected_output, f\"Failed on input: {input_date}\"\n",
    "\n",
    "\n",
    "test_format_fxstreet_date()\n",
    "\n",
    "\n",
    "def find_nearest_date_api(row, fxstreet_api_forecasts_dates):\n",
    "    \"\"\"\n",
    "    Finds the Actual_API value from fxstreet_api_forecasts corresponding to the nearest date\n",
    "    to the DateString in the given row.\n",
    "\n",
    "    Args:\n",
    "        row (pd.Series): A row from merged_price_window_0to2min DataFrame.\n",
    "        fxstreet_api_forecasts_dates (pd.Series): The Date_Formatted column from fxstreet_api_forecasts.\n",
    "\n",
    "    Returns:\n",
    "        float: The Actual_API value corresponding to the nearest date, or NaN if no match.\n",
    "    \"\"\"\n",
    "    date_to_match = row['DateString']\n",
    "\n",
    "    time_diffs = abs(fxstreet_api_forecasts_dates - date_to_match)\n",
    "\n",
    "    nearest_date_index = time_diffs.idxmin()\n",
    "\n",
    "    return fxstreet_api_forecasts['Actual_API'].iloc[nearest_date_index]\n",
    "\n",
    "mock_row = pd.Series({'DateString': '03/04/2025'})\n",
    "\n",
    "fxstreet_api_forecasts = pd.DataFrame({\n",
    "    'Date_Formatted': [\n",
    "        '03/04/2025',\n",
    "        '03/05/2025',\n",
    "        '03/03/2025',\n",
    "        '03/10/2025'\n",
    "    ],\n",
    "    'Actual_API': [65.0, 66.0, 64.0, 67.0]\n",
    "})\n",
    "\n",
    "fxstreet_api_forecasts['Date_Formatted'] = pd.to_datetime(fxstreet_api_forecasts['Date_Formatted'], format='%d/%m/%Y')\n",
    "\n",
    "fxstreet_api_forecasts_dates = fxstreet_api_forecasts['Date_Formatted']\n",
    "\n",
    "test_cases = [\n",
    "    (pd.Series({'DateString': '03/04/2025'}), 65.0),\n",
    "    (pd.Series({'DateString': '03/04/2025 12:00:00'}), 65.0),\n",
    "    (pd.Series({'DateString': '03/06/2025'}), 66.0),\n",
    "    (pd.Series({'DateString': '03/02/2025'}), 64.0),\n",
    "    (pd.Series({'DateString': '03/07/2025'}), 66.0),\n",
    "]\n",
    "\n",
    "def test_find_nearest_date_api():\n",
    "    for i, (mock_row, expected_output) in enumerate(test_cases):\n",
    "        if 'DateString' in mock_row:\n",
    "            try:\n",
    "                mock_row['DateString'] = pd.to_datetime(mock_row['DateString'], format='%d/%m/%Y %H:%M:%S')\n",
    "            except ValueError:\n",
    "                mock_row['DateString'] = pd.to_datetime(mock_row['DateString'], format='%d/%m/%Y')\n",
    "\n",
    "        actual_output = find_nearest_date_api(mock_row, fxstreet_api_forecasts_dates)\n",
    "\n",
    "        if expected_output is None:\n",
    "            assert pd.isna(actual_output), f\"Failed on input: {mock_row['DateString']}\"\n",
    "        else:\n",
    "            assert actual_output == expected_output, f\"Failed on input: {mock_row['DateString']}\"\n",
    "\n",
    "test_find_nearest_date_api()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f82369a-4b1d-4c5e-aaf6-b747b453a157",
   "metadata": {},
   "source": [
    "## Results\n",
    "Findings below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80cf38eb-73e5-498a-873a-2a4a814d5e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################################\n",
    "# FOR THE GRADER: You will notice that the outputs of project.ipynb and project.html look wildly #\n",
    "# different. We've talked to the prof about this already, the ipynb notebook is just there to    #\n",
    "# confirm that the code runs without error on a smaller dataset, while the .html file is output  #\n",
    "# produced by running the notebook locally on the full dataset.                                  #\n",
    "##################################################################################################\n",
    "\n",
    "'''\n",
    "Also if you are reading the .html project you may be wondering why none of the cells are\n",
    "producing output. I have added a %%capture to the top of cells that produce a plot, preventing\n",
    "the cells from outputting. I did this so I could embed the plots in markdown cells which I think\n",
    "is much easier than having to scroll through code while trying to read the research results. If\n",
    "you would rather have the plots show up next to the code, just comment out the %%capture line.\n",
    "'''\n",
    "\n",
    "pd.set_option('display.max_rows', 400)\n",
    "pd.set_option('display.max_columns', 20)\n",
    "\n",
    "icom_eia_forecasts = pd.read_csv('data/InvestingcomEIA.csv')\n",
    "fxstreet_api_forecasts = pd.read_csv('data/FXStreetAPI.csv')\n",
    "min_WTI = pd.read_csv(\n",
    "    'data/cl-1m.csv',\n",
    "    sep=';',\n",
    "    header=None,\n",
    "    names=['Date', 'Time', 'Open', 'High', 'Low', 'Close', 'Volume']\n",
    ")\n",
    "min_WTI = min_WTI[1225975:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e630cd9-9b64-4b48-bb98-f4f23d5b900a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4:50\n",
    "icom_eia_forecasts['Release_Datetime'] = icom_eia_forecasts.apply(standardize_eia_datetime, axis=1)\n",
    "\n",
    "eastern_tz = pytz.timezone('US/Eastern')\n",
    "icom_eia_forecasts['Release_Datetime_EST'] = icom_eia_forecasts['Release_Datetime'].dt.tz_localize(eastern_tz, ambiguous='infer', nonexistent='shift_forward')\n",
    "\n",
    "chicago_tz = pytz.timezone('America/Chicago')\n",
    "icom_eia_forecasts['Release_Datetime_CST'] = icom_eia_forecasts['Release_Datetime_EST'].dt.tz_convert(chicago_tz)\n",
    "\n",
    "min_WTI['Datetime'] = min_WTI.apply(standardize_wti_datetime, axis=1)\n",
    "\n",
    "min_WTI['Datetime_CST'] = min_WTI['Datetime'].dt.tz_localize(chicago_tz, ambiguous='infer', nonexistent='shift_forward')\n",
    "\n",
    "icom_eia_forecasts = icom_eia_forecasts.set_index('Release_Datetime_CST').sort_index()\n",
    "min_WTI = min_WTI.set_index('Datetime_CST').sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e27e2f1-6e2a-42d8-8e4c-59d1d9588199",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Histogram of EIA WPSR Crude Oil Supply Surprise\n",
    "# fig_hist_EIA_supply_surprise\n",
    "\n",
    "icom_eia_forecasts['supply_surprise'] = calculate_supply_surprise(icom_eia_forecasts)\n",
    "\n",
    "supply_surprise_data = icom_eia_forecasts['supply_surprise']\n",
    "\n",
    "fig_hist_EIA_supply_surprise = go.Figure(data=[go.Histogram(x=supply_surprise_data, nbinsx=100)])\n",
    "\n",
    "fig_hist_EIA_supply_surprise.update_layout(\n",
    "    title='Histogram of EIA WPSR Crude Oil Supply Surprise',\n",
    "    xaxis_title='Supply Surprise (Actual - Forecast, Million Barrels)',\n",
    "    yaxis_title='Frequency (Number of Releases)',\n",
    "    bargap=0.1\n",
    ")\n",
    "\n",
    "fig_hist_EIA_supply_surprise.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2775ca2-ef86-46a7-9a2c-4178d635ae41",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Histogram of One-Minute Percentage Price Changes in Crude Price\n",
    "# fig_hist_1min_wti\n",
    "# 1:41\n",
    "\n",
    "percentage_price_changes_1min_wti = []\n",
    "previous_close_price = None\n",
    "\n",
    "for index, row in min_WTI.iterrows():\n",
    "    current_close_price = row['Close']\n",
    "    if previous_close_price is not None and previous_close_price != 0:\n",
    "        percentage_change = ((current_close_price - previous_close_price) / previous_close_price) * 100.0\n",
    "        percentage_price_changes_1min_wti.append(percentage_change)\n",
    "    else:\n",
    "        percentage_price_changes_1min_wti.append(float('nan'))\n",
    "    previous_close_price = current_close_price\n",
    "\n",
    "percentage_price_changes_1min_wti_series = pd.Series(percentage_price_changes_1min_wti, index=min_WTI.index)\n",
    "min_WTI['Percent_Change'] = percentage_price_changes_1min_wti_series\n",
    "percentage_price_changes_1min_wti_series = percentage_price_changes_1min_wti_series.dropna()\n",
    "\n",
    "fig_hist_1min_wti = go.Figure(data=[go.Histogram(x=percentage_price_changes_1min_wti, nbinsx=1600)])\n",
    "\n",
    "fig_hist_1min_wti.update_layout(\n",
    "    title='Histogram of One-Minute Percentage Price Changes in Crude Price',\n",
    "    xaxis_title='One-Minute Percentage Price Change (%)',\n",
    "    yaxis_title='Frequency (Number of Minutes)',\n",
    "    xaxis_range=[-3, 3]\n",
    ")\n",
    "\n",
    "fig_hist_1min_wti.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fd14c7d7-420e-4747-ba94-902ee6498541",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Scatter plot of average trading volume one hour before and after the EIA WPSR release time\n",
    "# fig_volume_scatter_release\n",
    "\n",
    "price_window_60min = get_price_windows(icom_eia_forecasts.index, min_WTI, window_minutes_before=60, window_minutes_after=60)\n",
    "price_window_60min.sort_index(inplace=True)\n",
    "\n",
    "price_window_60min['Time_to_Release_Minutes'] = (price_window_60min.index - price_window_60min['Release_Datetime']).dt.total_seconds() / 60\n",
    "average_volume_by_time = price_window_60min.groupby('Time_to_Release_Minutes')['Volume'].mean().reset_index()\n",
    "\n",
    "fig_volume_scatter_release = go.Figure(data=[go.Scatter(\n",
    "    x=average_volume_by_time['Time_to_Release_Minutes'],\n",
    "    y=average_volume_by_time['Volume'],\n",
    "    mode='markers',\n",
    "    marker=dict(size=8),\n",
    "    text=average_volume_by_time['Volume'],\n",
    "    hovertemplate=\"Time to Release: %{x:.0f} minutes<br>Average Volume: %{y:.0f}<extra></extra>\"\n",
    ")])\n",
    "\n",
    "fig_volume_scatter_release.update_layout(\n",
    "    title='Average Trading Volume Around EIA WPSR Release',\n",
    "    xaxis_title='Minutes Relative to EIA Report Release',\n",
    "    yaxis_title='Average Volume',\n",
    "    xaxis=dict(\n",
    "        tickvals=[-60, -45, -30, -15, 0, 15, 30, 45, 60],\n",
    "        ticktext=['-60', '-45', '-30', '-15', 'Release', '+15', '+30', '+45', '+60']\n",
    "    ),\n",
    "    hovermode=\"closest\"\n",
    ")\n",
    "\n",
    "fig_volume_scatter_release.show()\n",
    "fig_volume_scatter_release.write_html(\"plots/fig_volume_scatter_release.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bb9417fd-2d50-499b-9184-9629959c7b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Two histograms indicating how prices move around the time of EIA WPSR release on days with a\n",
    "# release and days without a release\n",
    "# fig_heatmap_release\n",
    "# fig_heatmap_non_release\n",
    "\n",
    "\n",
    "price_window_60min['Time_Delta_Minutes'] = (price_window_60min.index - price_window_60min['Release_Datetime']).dt.total_seconds() / 60\n",
    "\n",
    "time_intervals_release = sorted(price_window_60min['Time_Delta_Minutes'].unique())\n",
    "price_change_bins = np.linspace(-1, 1, num=41)\n",
    "price_change_labels = [f'{bin_val:.2f}%' for bin_val in price_change_bins]\n",
    "\n",
    "price_window_60min['Price_Change_Bin'] = pd.cut(price_window_60min['Percent_Change'], bins=price_change_bins, labels=price_change_labels[:-1], include_lowest=True)\n",
    "\n",
    "\n",
    "heatmap_data_release = price_window_60min.groupby(['Price_Change_Bin', 'Time_Delta_Minutes'], observed=False).size().unstack(fill_value=0)\n",
    "\n",
    "heatmap_data_release = heatmap_data_release.reindex(columns=time_intervals_release, fill_value=0)\n",
    "heatmap_data_release = heatmap_data_release.reindex(index=price_change_labels[:-1], fill_value=0)\n",
    "\n",
    "fig_heatmap_release = go.Figure(data=go.Heatmap(\n",
    "    z=heatmap_data_release.values,\n",
    "    x=heatmap_data_release.columns,\n",
    "    y=heatmap_data_release.index,\n",
    "    colorscale='Viridis',\n",
    "    colorbar=dict(title='Frequency')\n",
    "))\n",
    "\n",
    "fig_heatmap_release.update_layout(\n",
    "    title='Frequency of Percentage Price Changes Around EIA WPSR Release',\n",
    "    xaxis_title='Time Relative to Release (Minutes)',\n",
    "    yaxis_title='Percentage Price Change Bins',\n",
    "    yaxis=dict(autorange=\"reversed\"),\n",
    "    xaxis=dict(tickvals=time_intervals_release[::5], ticktext=[int(x) for x in time_intervals_release[::5]])\n",
    ")\n",
    "\n",
    "\n",
    "eia_release_dates = icom_eia_forecasts.reset_index()['Release_Datetime_CST'].dt.date\n",
    "min_wti_dates = min_WTI.reset_index()['Datetime_CST'].dt.date\n",
    "mask_non_eia_days = ~min_wti_dates.isin(eia_release_dates)\n",
    "\n",
    "min_WTI_no_eia_days = min_WTI.reset_index()[mask_non_eia_days].copy()\n",
    "\n",
    "wti_with_eia_releases = pd.merge_asof(\n",
    "    left=min_WTI_no_eia_days.reset_index(),\n",
    "    right=icom_eia_forecasts.reset_index(),\n",
    "    left_on='Datetime_CST',\n",
    "    right_on='Release_Datetime_CST',\n",
    "    direction='nearest',\n",
    "    tolerance=pd.Timedelta('2D')\n",
    ")\n",
    "\n",
    "wti_with_eia_releases = wti_with_eia_releases.set_index('Datetime_CST')\n",
    "\n",
    "wti_with_eia_releases.dropna(subset=['Release_Datetime_CST'], inplace=True)\n",
    "\n",
    "time_diff = [time_difference(t1, t2) for t1, t2 in zip(wti_with_eia_releases.reset_index()['Release_Datetime_CST'].dt.time, wti_with_eia_releases.reset_index()['Datetime_CST'].dt.time)]\n",
    "\n",
    "time_diff_series = pd.Series(time_diff)\n",
    "wti_with_eia_releases.reset_index(inplace=True)\n",
    "wti_with_eia_releases['Time_till_Release'] = (time_diff_series)\n",
    "wti_with_eia_releases.set_index('Datetime_CST', inplace=True)\n",
    "\n",
    "non_release_price_windows_60min = wti_with_eia_releases.copy().loc[wti_with_eia_releases['Time_till_Release'].abs() <= 60.0]\n",
    "non_release_price_windows_60min.reset_index(inplace=True)\n",
    "non_release_price_windows_60min.drop(columns=['Datetime_CST', 'Open', 'High', 'Low', 'Close', 'Release_Datetime_CST', 'Release_Datetime_EST'], inplace=True)\n",
    "\n",
    "time_intervals_non_release = sorted(non_release_price_windows_60min['Time_till_Release'].unique())\n",
    "\n",
    "non_release_price_windows_60min['Price_Change_Bin'] = pd.cut(non_release_price_windows_60min['Percent_Change'], bins=price_change_bins, labels=price_change_labels[:-1], include_lowest=True)\n",
    "\n",
    "\n",
    "heatmap_data_non_release = non_release_price_windows_60min.groupby(['Price_Change_Bin', 'Time_till_Release'], observed=False).size().unstack(fill_value=0)\n",
    "\n",
    "heatmap_data_non_release = heatmap_data_non_release.reindex(columns=time_intervals_non_release, fill_value=0)\n",
    "heatmap_data_non_release = heatmap_data_non_release.reindex(index=price_change_labels[:-1], fill_value=0)\n",
    "\n",
    "heatmap_non_release_values = heatmap_data_non_release.values\n",
    "\n",
    "min_val = np.min(heatmap_non_release_values)\n",
    "max_val = np.max(heatmap_non_release_values)\n",
    "\n",
    "if max_val > min_val:\n",
    "    heatmap_non_release_values_scaled_linear = (heatmap_non_release_values - min_val) / (max_val - min_val) * 100.0\n",
    "else:\n",
    "    heatmap_non_release_values_scaled_linear = np.zeros_like(heatmap_non_release_values)\n",
    "\n",
    "fig_heatmap_non_release = go.Figure(data=go.Heatmap(\n",
    "    z=heatmap_non_release_values_scaled_linear,\n",
    "    x=heatmap_data_non_release.columns,\n",
    "    y=heatmap_data_non_release.index,\n",
    "    colorscale='Viridis',\n",
    "    colorbar=dict(title='Frequency')\n",
    "))\n",
    "\n",
    "fig_heatmap_non_release.update_layout(\n",
    "    title='Frequency of Percentage Price Changes Around EIA WPSR Release On Non-Release Days',\n",
    "    xaxis_title='Time Relative to Release (Minutes)',\n",
    "    yaxis_title='Percentage Price Change Bins',\n",
    "    xaxis=dict(tickvals=time_intervals_non_release[::5], ticktext=[int(x) for x in time_intervals_non_release[::5]])\n",
    ")\n",
    "\n",
    "fig_heatmap_release.show()\n",
    "fig_heatmap_non_release.show()\n",
    "fig_heatmap_release.write_html(\"plots/fig_heatmap_release.html\")\n",
    "fig_heatmap_non_release.write_html(\"plots/fig_heatmap_non_release.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d702d6a0-a1f6-4c88-88d9-e8464d930b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Line plot showing how the p-value of a two-sample Kolmogorov-Smirnov statistical test comparing\n",
    "# post-release price distributions on days with and without release changes with each minute.\n",
    "#\n",
    "# line_plot_p_value_KS_test = create_ks_test_p_value_plot(ks_results_df)\n",
    "\n",
    "price_change_bins_labels = heatmap_data_non_release.index\n",
    "price_change_bins_midpoints = []\n",
    "for label in price_change_bins_labels:\n",
    "    lower_bound_str = label.split('%')[0]\n",
    "    midpoint = float(lower_bound_str) / 100.0\n",
    "    price_change_bins_midpoints.append(midpoint)\n",
    "price_change_bins_midpoints = np.array(price_change_bins_midpoints)\n",
    "\n",
    "minutes_to_test =pd.Series([float(m) for m in range(0, 16)])\n",
    "\n",
    "ks_results = []\n",
    "\n",
    "for minute in minutes_to_test:\n",
    "    if minute not in heatmap_data_non_release.columns or minute not in heatmap_data_release.columns:\n",
    "        print(f\"Minute {minute} not found in both heatmaps. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    sample_non_release = []\n",
    "    frequencies_non_release = heatmap_data_non_release[minute]\n",
    "    for i, freq in enumerate(frequencies_non_release):\n",
    "        sample_non_release.extend([price_change_bins_midpoints[i]] * freq)\n",
    "    sample_non_release = np.array(sample_non_release)\n",
    "\n",
    "    sample_release = []\n",
    "    frequencies_release = heatmap_data_release[minute]\n",
    "    for i, freq in enumerate(frequencies_release):\n",
    "        sample_release.extend([price_change_bins_midpoints[i]] * freq)\n",
    "    sample_release = np.array(sample_release)\n",
    "\n",
    "    if sample_non_release.size > 0 and sample_release.size > 0:\n",
    "        ks_statistic, p_value = stats.ks_2samp(sample_non_release, sample_release)\n",
    "        ks_results.append({\n",
    "            'Minute': float(minute),\n",
    "            'KS Statistic': ks_statistic,\n",
    "            'P-value': p_value\n",
    "        })\n",
    "    else:\n",
    "        ks_results.append({\n",
    "            'Minute': float(minute),\n",
    "            'KS Statistic': np.nan,\n",
    "            'P-value': np.nan,\n",
    "            'Warning': 'One or both samples are empty, KS test not performed.'\n",
    "        })\n",
    "\n",
    "ks_results_df = pd.DataFrame(ks_results)\n",
    "\n",
    "def create_ks_test_p_value_plot(ks_results_df):\n",
    "    \"\"\"\n",
    "    Generates a line plot of KS test P-values for price change distributions.\n",
    "\n",
    "    Args:\n",
    "        ks_results_df: DataFrame containing 'Minute' and 'P-value' columns.\n",
    "\n",
    "    Returns:\n",
    "        matplotlib.figure.Figure: The generated plot figure.\n",
    "    \"\"\"\n",
    "    line_plot_p_value_KS_test = plt.figure(figsize=(10, 6))\n",
    "    plt.plot(ks_results_df['Minute'], ks_results_df['P-value'], marker='o', linestyle='-')\n",
    "    plt.axhline(0.1, color='r', linestyle='--', label='Significance Level (0.1)')\n",
    "    plt.title('KS Test P-values for Price Change Distributions (Release vs. Non-Release Days)')\n",
    "    plt.xlabel('Minutes Relative to Release')\n",
    "    plt.ylabel('P-value')\n",
    "    plt.xticks(ks_results_df['Minute'])\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    return line_plot_p_value_KS_test\n",
    "\n",
    "line_plot_p_value_KS_test = create_ks_test_p_value_plot(ks_results_df)\n",
    "line_plot_p_value_KS_test.savefig('plots/line_plot_p_vaue_KS_test.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1067e9dd-c456-4563-b294-f2d2d9ef3471",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Scatter Plot of Supply Surprise (Investing.com) vs. Percentage Price Change (0-2 min)\n",
    "# fig_scatter_surprise_vs_pricechange_Investingcom\n",
    "# surprise_vs_pricechange_Investingcom_r_2\n",
    "\n",
    "\n",
    "price_window_0to2min = price_window_60min[\n",
    "    (price_window_60min['Time_to_Release_Minutes'] >= 0.0) & (price_window_60min['Time_to_Release_Minutes'] <= 2.0) #delta\n",
    "]\n",
    "\n",
    "merged_price_window_0to2min = pd.merge(\n",
    "    price_window_0to2min.reset_index(),\n",
    "    icom_eia_forecasts.reset_index()[['Release_Datetime_CST', 'supply_surprise', 'Actual', 'Forecast', 'Previous']],\n",
    "    left_on='Release_Datetime',\n",
    "    right_on='Release_Datetime_CST',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "merged_price_window_0to2min = merged_price_window_0to2min.drop(columns=['Release_Datetime_CST'])\n",
    "\n",
    "merged_price_window_0to2min['Date'] = str(merged_price_window_0to2min['Date'])\n",
    "\n",
    "date_string_series = merged_price_window_0to2min['Datetime_CST'].dt.strftime('%d/%m/%Y')\n",
    "merged_price_window_0to2min['Date'] = date_string_series\n",
    "\n",
    "fxstreet_api_forecasts['Date_Formatted'] = fxstreet_api_forecasts['Date'].apply(format_fxstreet_date)\n",
    "fxstreet_api_forecasts['Date_Formatted'] = pd.to_datetime(fxstreet_api_forecasts['Date_Formatted'], format='%d/%m/%Y').dt.date\n",
    "\n",
    "fxstreet_api_forecasts['Actual_API'] = fxstreet_api_forecasts['Actual']\n",
    "fxstreet_api_forecasts['Actual_API'] = fxstreet_api_forecasts['Actual_API'].astype('float')\n",
    "\n",
    "\n",
    "merged_price_window_0to2min['DateString'] = pd.to_datetime(merged_price_window_0to2min['Date'], format='%d/%m/%Y')\n",
    "fxstreet_api_forecasts['Date_Formatted'] = pd.to_datetime(fxstreet_api_forecasts['Date_Formatted'], format='%d/%m/%Y')\n",
    "\n",
    "merged_price_window_0to2min_api = merged_price_window_0to2min.copy()\n",
    "merged_price_window_0to2min_api['Actual_API'] = merged_price_window_0to2min_api.apply(\n",
    "    find_nearest_date_api,\n",
    "    axis=1,\n",
    "    args=(fxstreet_api_forecasts['Date_Formatted'],)\n",
    ")\n",
    "\n",
    "merged_price_window_0to2min_api = merged_price_window_0to2min_api[678:]\n",
    "\n",
    "grouped_by_date = merged_price_window_0to2min.groupby('Date')\n",
    "\n",
    "date_percentage_changes = []\n",
    "\n",
    "for date, group_df in grouped_by_date:\n",
    "    earliest_minute_row = group_df.sort_values(by='Datetime_CST').iloc[0]\n",
    "    earliest_close_price = earliest_minute_row['Close']\n",
    "\n",
    "    latest_minute_row = group_df.sort_values(by='Datetime_CST').iloc[-1]\n",
    "    latest_close_price = latest_minute_row['Close']\n",
    "\n",
    "    if earliest_close_price != 0:\n",
    "        percentage_change = ((latest_close_price - earliest_close_price) / earliest_close_price) * 100.0\n",
    "    else:\n",
    "        percentage_change = float('nan')\n",
    "\n",
    "    date_percentage_changes.append({\n",
    "        'Date': date,\n",
    "        'Start_Datetime': earliest_minute_row['Datetime_CST'],\n",
    "        'End_Datetime': latest_minute_row['Datetime_CST'],\n",
    "        'Start_Price': earliest_close_price,\n",
    "        'End_Price': latest_close_price,\n",
    "        'Percentage_Change_0to2min': percentage_change,\n",
    "        'supply_surprise': earliest_minute_row['supply_surprise'],\n",
    "        'Actual' : float(str(earliest_minute_row['Actual']).replace('M', '')),\n",
    "        'Forecast' : float(str(earliest_minute_row['Forecast']).replace('M', '')),\n",
    "        'Previous' : float(str(earliest_minute_row['Previous']).replace('M', ''))\n",
    "    })\n",
    "\n",
    "date_percentage_change_df = pd.DataFrame(date_percentage_changes) # icom\n",
    "\n",
    "\n",
    "date_percentage_change_df['Start_Datetime'] = pd.to_datetime(date_percentage_change_df['Start_Datetime'])\n",
    "\n",
    "min_datetime = date_percentage_change_df['Start_Datetime'].min()\n",
    "max_datetime = date_percentage_change_df['Start_Datetime'].max()\n",
    "\n",
    "date_percentage_change_df['Time_Proportion'] = (date_percentage_change_df['Start_Datetime'] - min_datetime) / (max_datetime - min_datetime)\n",
    "\n",
    "if (max_datetime - min_datetime) == pd.Timedelta(0):\n",
    "    date_percentage_change_df['Time_Proportion'] = 0.5\n",
    "\n",
    "not_nan_mask = date_percentage_change_df['supply_surprise'].notna()\n",
    "\n",
    "date_percentage_change_df = date_percentage_change_df[not_nan_mask]\n",
    "\n",
    "nan_mask = date_percentage_change_df['supply_surprise'].isna()\n",
    "\n",
    "nan_count = nan_mask.sum()\n",
    "\n",
    "nan_rows = date_percentage_change_df[nan_mask]\n",
    "\n",
    "X = date_percentage_change_df['supply_surprise']\n",
    "y = date_percentage_change_df['Percentage_Change_0to2min']\n",
    "\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "model = sm.OLS(y, X)\n",
    "results = model.fit()\n",
    "\n",
    "surprise_vs_pricechange_Investingcom_r_2 = results.rsquared\n",
    "\n",
    "print(\"\\n--- Coefficients ---\")\n",
    "print(results.params)\n",
    "print(\"\\n--- R-squared ---\")\n",
    "print(f\"R-squared: {results.rsquared}\")\n",
    "\n",
    "fig_scatter_surprise_vs_pricechange_Investingcom = px.scatter(\n",
    "    date_percentage_change_df,\n",
    "    x='supply_surprise',\n",
    "    y='Percentage_Change_0to2min',\n",
    "    color='Time_Proportion',\n",
    "    hover_data=['Date', 'Start_Datetime', 'End_Datetime', 'Start_Price', 'End_Price'],\n",
    "    title='Scatter Plot of Supply Surprise (Investing.com) vs. Percentage Price Change (0-2 min)',\n",
    "    labels={\n",
    "        'supply_surprise': 'EIA WPSR Supply Surprise (Millions of Barrels)',\n",
    "        'Percentage_Change_0to2min': 'Percentage Price Change (0-2 min)',\n",
    "        'Time_Proportion': 'Time Progression'\n",
    "    },\n",
    "    color_continuous_scale=px.colors.sequential.Viridis\n",
    ")\n",
    "\n",
    "fig_scatter_surprise_vs_pricechange_Investingcom.update_layout(\n",
    "    xaxis_title='EIA WPSR Supply Surprise (Millions of Barrels)',\n",
    "    yaxis_title='Percentage Price Change (0-2 min)'\n",
    ")\n",
    "\n",
    "fig_scatter_surprise_vs_pricechange_Investingcom.show()\n",
    "fig_scatter_surprise_vs_pricechange_Investingcom.write_html(\"plots/fig_scatter_surprise_vs_pricechange_Investingcom.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e88afd-57b9-4b4e-8b37-17ed789b4fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Scatter Plot of Supply Surprise (API) vs. Percentage Price Change (0-2 min)\n",
    "# fig_scatter_surprise_vs_pricechange_api\n",
    "# surprise_vs_pricechange_API_r_2\n",
    "\n",
    "grouped_by_date_api = merged_price_window_0to2min_api.groupby('Date')\n",
    "\n",
    "date_percentage_changes_api = []\n",
    "\n",
    "for date, group_df in grouped_by_date_api:\n",
    "    earliest_minute_row = group_df.sort_values(by='Datetime_CST').iloc[0]\n",
    "    earliest_close_price = earliest_minute_row['Close']\n",
    "\n",
    "    latest_minute_row = group_df.sort_values(by='Datetime_CST').iloc[-1]\n",
    "    latest_close_price = latest_minute_row['Close']\n",
    "\n",
    "    if earliest_close_price != 0:\n",
    "        percentage_change = ((latest_close_price - earliest_close_price) / earliest_close_price) * 100.0\n",
    "    else:\n",
    "        percentage_change = float('nan')\n",
    "\n",
    "    date_percentage_changes_api.append({\n",
    "        'Date': date,\n",
    "        'Start_Datetime': earliest_minute_row['Datetime_CST'],\n",
    "        'End_Datetime': latest_minute_row['Datetime_CST'],\n",
    "        'Start_Price': earliest_close_price,\n",
    "        'End_Price': latest_close_price,\n",
    "        'Percentage_Change_0to2min': percentage_change,\n",
    "        'supply_surprise': float(str(earliest_minute_row['Actual']).replace('M', '')) - earliest_minute_row['Actual_API'],\n",
    "        'Actual_API' : earliest_minute_row['Actual_API'],\n",
    "        'Actual_EIA' : earliest_minute_row['Actual']\n",
    "    })\n",
    "\n",
    "date_percentage_change_df_api = pd.DataFrame(date_percentage_changes_api) # api\n",
    "\n",
    "\n",
    "date_percentage_change_df_api_sorted = date_percentage_change_df_api.sort_values(by='supply_surprise')\n",
    "\n",
    "date_percentage_change_df_api_sorted['Start_Datetime'] = pd.to_datetime(date_percentage_change_df_api_sorted['Start_Datetime'])\n",
    "\n",
    "min_datetime = date_percentage_change_df_api_sorted['Start_Datetime'].min()\n",
    "max_datetime = date_percentage_change_df_api_sorted['Start_Datetime'].max()\n",
    "\n",
    "date_percentage_change_df_api_sorted['Time_Proportion'] = (date_percentage_change_df_api_sorted['Start_Datetime'] - min_datetime) / (max_datetime - min_datetime)\n",
    "\n",
    "\n",
    "X = date_percentage_change_df_api_sorted['supply_surprise']\n",
    "y = date_percentage_change_df_api_sorted['Percentage_Change_0to2min']\n",
    "\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "model = sm.OLS(y, X)\n",
    "results = model.fit()\n",
    "\n",
    "surprise_vs_pricechange_API_r_2 = results.rsquared\n",
    "\n",
    "print(\"\\n--- Coefficients ---\")\n",
    "print(results.params)\n",
    "print(\"\\n--- R-squared ---\")\n",
    "print(f\"R-squared: {results.rsquared}\")\n",
    "\n",
    "fig_scatter_surprise_vs_pricechange_api = px.scatter(\n",
    "    date_percentage_change_df_api_sorted,\n",
    "    x='supply_surprise',\n",
    "    y='Percentage_Change_0to2min',\n",
    "    color='Time_Proportion',\n",
    "    hover_data=['Date', 'Start_Datetime', 'End_Datetime', 'Start_Price', 'End_Price'],\n",
    "    title='Scatter Plot of Supply Surprise (API) vs. Percentage Price Change (0-2 min)',\n",
    "    labels={\n",
    "        'supply_surprise': 'EIA WPSR Supply Surprise (Millions of Barrels)',\n",
    "        'Percentage_Change_0to2min': 'Percentage Price Change (0-2 min)',\n",
    "        'Time_Proportion': 'Time Progression'\n",
    "    },\n",
    "    color_continuous_scale=px.colors.sequential.Viridis\n",
    ")\n",
    "\n",
    "fig_scatter_surprise_vs_pricechange_api.update_layout(\n",
    "    xaxis_title='EIA WPSR Supply Surprise (Millions of Barrels)',\n",
    "    yaxis_title='Percentage Price Change (0-2 min)'\n",
    ")\n",
    "\n",
    "fig_scatter_surprise_vs_pricechange_api.show()\n",
    "\n",
    "fig_scatter_surprise_vs_pricechange_api.write_html(\"plots/fig_scatter_surprise_vs_pricechange_api.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "472324a5-1c17-4ebe-8150-3bc0c86b71f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Scatter Plot of Supply Change (EIA) vs. Percentage Price Change (0-2 min)\n",
    "# fig_scatter_surprise_vs_pricechange_EIA\n",
    "# surprise_vs_pricechange_EIA_r_2\n",
    "\n",
    "date_percentage_change_df_sorted = date_percentage_change_df.sort_values(by='Actual')\n",
    "\n",
    "X = date_percentage_change_df_sorted['Actual']\n",
    "y = date_percentage_change_df_sorted['Percentage_Change_0to2min']\n",
    "\n",
    "X = sm.add_constant(X)\n",
    "model = sm.OLS(y, X)\n",
    "results = model.fit()\n",
    "\n",
    "surprise_vs_pricechange_EIA_r_2 = results.rsquared\n",
    "\n",
    "print(\"\\n--- Coefficients ---\")\n",
    "print(results.params)\n",
    "print(\"\\n--- R-squared ---\")\n",
    "print(f\"R-squared: {results.rsquared}\")\n",
    "\n",
    "\n",
    "fig_scatter_surprise_vs_pricechange_EIA = px.scatter(\n",
    "    date_percentage_change_df_sorted,\n",
    "    x='Actual',\n",
    "    y='Percentage_Change_0to2min',\n",
    "    color='Time_Proportion',\n",
    "    hover_data=['Date', 'Start_Datetime', 'End_Datetime', 'Start_Price', 'End_Price'],\n",
    "    title='Scatter Plot of Supply Change (EIA) vs. Percentage Price Change (0-2 min)',\n",
    "    labels={\n",
    "        'Actual': 'EIA WPSR Supply Surprise (Millions of Barrels)',\n",
    "        'Percentage_Change_0to2min': 'Percentage Price Change (0-2 min)',\n",
    "        'Time_Proportion': 'Time Progression'\n",
    "    },\n",
    "    color_continuous_scale=px.colors.sequential.Viridis\n",
    ")\n",
    "\n",
    "fig_scatter_surprise_vs_pricechange_EIA.update_layout(\n",
    "    xaxis_title='EIA WPSR Supply Change (Millions of Barrels)',\n",
    "    yaxis_title='Percentage Price Change (0-2 min)'\n",
    ")\n",
    "\n",
    "fig_scatter_surprise_vs_pricechange_EIA.show()\n",
    "\n",
    "fig_scatter_surprise_vs_pricechange_EIA.write_html(\"plots/fig_scatter_surprise_vs_pricechange_EIA.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3d28d093-8123-4910-b299-6d24ee15cee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Kernel Regression: Actual vs. Predicted Values\n",
    "# kernel_reg_plot\n",
    "# mse_Kernel_Regression\n",
    "# r2_Kernel_Regression\n",
    "\n",
    "X = date_percentage_change_df_sorted[['Actual']]\n",
    "y = date_percentage_change_df_sorted['Percentage_Change_0to2min']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    \"alpha\": np.logspace(-3, 3, 7),\n",
    "    \"gamma\": np.logspace(-3, 3, 7)\n",
    "}\n",
    "\n",
    "kernel_reg = KernelRidge(kernel='rbf')\n",
    "\n",
    "grid_search = GridSearchCV(kernel_reg, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_kernel_reg = grid_search.best_estimator_\n",
    "\n",
    "y_pred_test = best_kernel_reg.predict(X_test)\n",
    "mse_Kernel_Regression = mean_squared_error(y_test, y_pred_test)\n",
    "r2_Kernel_Regression = r2_score(y_test, y_pred_test)\n",
    "\n",
    "print(f\"Best Kernel Regression model (Gaussian Kernel) with hyperparameters: {grid_search.best_params_}\")\n",
    "print(f\"Mean Squared Error on Test Set: {mse_Kernel_Regression:.4f}\")\n",
    "print(f\"R-squared on Test Set: {r2_Kernel_Regression:.4f}\")\n",
    "\n",
    "def create_kernel_regression_plot(X_test, y_test, y_pred_test):\n",
    "    \"\"\"\n",
    "    Generates a scatter plot comparing actual vs. predicted values from a Kernel Regression model.\n",
    "\n",
    "    Args:\n",
    "        X_test (pd.DataFrame): DataFrame containing the test features, including 'Actual' column.\n",
    "        y_test (pd.Series): Series of actual target values.\n",
    "        y_pred_test (np.ndarray): Array of predicted target values from the Kernel Regression model.\n",
    "\n",
    "    Returns:\n",
    "        matplotlib.figure.Figure: The matplotlib Figure object containing the plot.\n",
    "                                  This can be stored and displayed later.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    ax.scatter(X_test['Actual'], y_test, color='blue', label='Actual Values', alpha=0.7)\n",
    "    ax.scatter(X_test['Actual'], y_pred_test, color='red', label='Kernel Regression Predictions', alpha=0.7)\n",
    "\n",
    "    ax.set_xlabel('Actual')\n",
    "    ax.set_ylabel('Percentage_Change_0to2min')\n",
    "    ax.set_title('Kernel Regression: Actual vs. Predicted Values')\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "\n",
    "    return fig\n",
    "\n",
    "kernel_reg_plot = create_kernel_regression_plot(X_test, y_test, y_pred_test)\n",
    "\n",
    "kernel_reg_plot.savefig('plots/kernel_reg_plot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "65fdbf2b-26f3-4e12-807f-2284bc02fbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# LOESS Regression: Percentage Change vs Actual\n",
    "# loess_plot\n",
    "# mse_loess\n",
    "# r2_loess\n",
    "\n",
    "y = date_percentage_change_df_sorted['Percentage_Change_0to2min']\n",
    "X = date_percentage_change_df_sorted['Actual']\n",
    "\n",
    "lowess = sm.nonparametric.lowess(y, X, frac=0.3)\n",
    "\n",
    "x_fitted = lowess[:, 0]\n",
    "y_fitted = lowess[:, 1]\n",
    "\n",
    "date_percentage_change_df_sorted['LOESS_Fitted_Percentage_Change'] = np.interp(X, x_fitted, y_fitted)\n",
    "\n",
    "mse_loess = mean_squared_error(y, date_percentage_change_df_sorted['LOESS_Fitted_Percentage_Change'])\n",
    "r2_loess = r2_score(y, date_percentage_change_df_sorted['LOESS_Fitted_Percentage_Change'])\n",
    "\n",
    "print(f\"Mean Squared Error (MSE) of the LOESS model: {mse_loess:.6f}\")\n",
    "print(f\"R-squared (R2) of the LOESS model: {r2_loess:.6f}\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "ax.scatter(X, y, label='Observed Data', alpha=0.6)\n",
    "ax.plot(x_fitted, y_fitted, color='red', label='LOESS Fit')\n",
    "ax.set_xlabel('Actual')\n",
    "ax.set_ylabel('Percentage_Change_0to2min')\n",
    "ax.set_title('LOESS Regression: Percentage Change vs Actual')\n",
    "ax.legend()\n",
    "ax.grid(True)\n",
    "\n",
    "fig.savefig('plots/loess.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "59438f9e-e0e7-44d6-913d-055743ca1ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# rf_feature_fig\n",
    "# xgb_feature_fig\n",
    "# rf_actual_pred_fig\n",
    "# xgb_actual_pred_fig\n",
    "# rf_mse\n",
    "# rf_r2\n",
    "# xgb_mse\n",
    "# xgb_r2\n",
    "\n",
    "X = date_percentage_change_df_sorted[['Actual', 'Forecast', 'Start_Price']]\n",
    "y = date_percentage_change_df_sorted['Percentage_Change_0to2min']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [40, 50, 60],\n",
    "    'max_depth': [1, 5],\n",
    "    'min_samples_split': [2, 3, 4, 5],\n",
    "    'min_samples_leaf': [4, 5, 6, 7]\n",
    "}\n",
    "\n",
    "param_grid_xgb = {\n",
    "    'n_estimators': [10, 15, 20, 25],\n",
    "    'max_depth': [1, 3, 5, 7, 9, 11],\n",
    "    'learning_rate': [0.0001, 0.001, 0.005],\n",
    "    'subsample': [0.5, 0.6, 0.7],\n",
    "    'colsample_bytree': [0.7, 0.8, 0.9]\n",
    "}\n",
    "\n",
    "grid_search_rf = GridSearchCV(estimator=RandomForestRegressor(random_state=42),\n",
    "                           param_grid=param_grid_rf,\n",
    "                           scoring='neg_mean_squared_error',\n",
    "                           cv=3,\n",
    "                           n_jobs=-1)\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "best_rf_model = grid_search_rf.best_estimator_\n",
    "\n",
    "grid_search_xgb = GridSearchCV(estimator=XGBRegressor(objective='reg:squarederror', random_state=42),\n",
    "                            param_grid=param_grid_xgb,\n",
    "                            scoring='neg_mean_squared_error',\n",
    "                            cv=3,\n",
    "                            n_jobs=-1)\n",
    "grid_search_xgb.fit(X_train, y_train)\n",
    "best_xgb_model = grid_search_xgb.best_estimator_\n",
    "\n",
    "\n",
    "rf_predictions = best_rf_model.predict(X_test)\n",
    "xgb_predictions = best_xgb_model.predict(X_test)\n",
    "\n",
    "rf_mse = mean_squared_error(y_test, rf_predictions)\n",
    "rf_r2 = r2_score(y_test, rf_predictions)\n",
    "\n",
    "xgb_mse = mean_squared_error(y_test, xgb_predictions)\n",
    "xgb_r2 = r2_score(y_test, xgb_predictions)\n",
    "\n",
    "print(\"Best Random Forest Regressor Performance (after GridSearchCV):\")\n",
    "print(f\"  Mean Squared Error: {rf_mse:.4f}\")\n",
    "print(f\"  R-squared: {rf_r2:.4f}\")\n",
    "print(f\"  Best parameters: {grid_search_rf.best_params_}\")\n",
    "\n",
    "print(\"\\nBest XGBoost Regressor Performance (after GridSearchCV):\")\n",
    "print(f\"  Mean Squared Error: {xgb_mse:.4f}\")\n",
    "print(f\"  R-squared: {xgb_r2:.4f}\")\n",
    "print(f\"  Best parameters: {grid_search_xgb.best_params_}\")\n",
    "\n",
    "\n",
    "def plot_feature_importance(best_rf_model, best_xgb_model, X):\n",
    "    \"\"\"\n",
    "    Generates and returns two separate matplotlib figure objects for feature importance plots\n",
    "    for Random Forest and XGBoost models.\n",
    "\n",
    "    Args:\n",
    "        best_rf_model: Trained Random Forest model object.\n",
    "        best_xgb_model: Trained XGBoost model object.\n",
    "        X: DataFrame used for training, needed for column names.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing two matplotlib.figure.Figure objects:\n",
    "               (rf_feature_importance_fig, xgb_feature_importance_fig)\n",
    "    \"\"\"\n",
    "    rf_feature_importance_fig = plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 1, 1)\n",
    "    rf_feature_importance = pd.Series(best_rf_model.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "    rf_feature_importance.plot(kind='bar')\n",
    "    plt.title('Best Random Forest - Feature Importance')\n",
    "    plt.ylabel('Importance Score')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    xgb_feature_importance_fig = plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 1, 1)\n",
    "    xgb_feature_importance = pd.Series(best_xgb_model.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "    xgb_feature_importance.plot(kind='bar')\n",
    "    plt.title('Best XGBoost - Feature Importance')\n",
    "    plt.ylabel('Importance Score')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    return rf_feature_importance_fig, xgb_feature_importance_fig\n",
    "\n",
    "\n",
    "def plot_actual_vs_predicted(y_test, rf_predictions, xgb_predictions):\n",
    "    \"\"\"\n",
    "    Generates and returns two separate matplotlib figure objects for Actual vs. Predicted plots\n",
    "    for Random Forest and XGBoost models.\n",
    "\n",
    "    Args:\n",
    "        y_test: Actual target values.\n",
    "        rf_predictions: Predictions from the Best Random Forest model.\n",
    "        xgb_predictions: Predictions from the Best XGBoost model.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing two matplotlib.figure.Figure objects:\n",
    "               (rf_actual_vs_predicted_fig, xgb_actual_vs_predicted_fig)\n",
    "    \"\"\"\n",
    "    rf_actual_vs_predicted_fig = plt.figure(figsize=(6, 6))\n",
    "    plt.subplot(1, 1, 1)\n",
    "    plt.scatter(y_test, rf_predictions)\n",
    "    plt.xlabel('Actual Percentage Change')\n",
    "    plt.ylabel('Predicted Percentage Change (Best Random Forest)')\n",
    "    plt.title('Best Random Forest: Actual vs. Predicted')\n",
    "    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    xgb_actual_vs_predicted_fig = plt.figure(figsize=(6, 6))\n",
    "    plt.subplot(1, 1, 1)\n",
    "    plt.scatter(y_test, xgb_predictions)\n",
    "    plt.xlabel('Actual Percentage Change')\n",
    "    plt.ylabel('Predicted Percentage Change (Best XGBoost)')\n",
    "    plt.title('Best XGBoost: Actual vs. Predicted')\n",
    "    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    return rf_actual_vs_predicted_fig, xgb_actual_vs_predicted_fig\n",
    "\n",
    "rf_feature_fig, xgb_feature_fig = plot_feature_importance(best_rf_model, best_xgb_model, X)\n",
    "\n",
    "rf_feature_fig.savefig('plots/rf_feature_fig.png')\n",
    "xgb_feature_fig.savefig('plots/xgb_feature_fig.png')\n",
    "\n",
    "rf_actual_pred_fig, xgb_actual_pred_fig = plot_actual_vs_predicted(y_test, rf_predictions, xgb_predictions)\n",
    "\n",
    "rf_actual_pred_fig.savefig('plots/rf_actual_pred_fig.png')\n",
    "xgb_actual_pred_fig.savefig('plots/xgb_actual_pred_fig.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "162b55a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# mse_ridge\n",
    "# r2_ridge\n",
    "# prediction_plot_ridge_reg\n",
    "# mse_baseline\n",
    "# r2_baseline\n",
    "\n",
    "def ridge_regression_for_price_change(dataframe):\n",
    "    \"\"\"\n",
    "    Fits a Ridge regression model and calculates performance metrics.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        X = dataframe[['Actual', 'Start_Price']]\n",
    "        y = dataframe['Percentage_Change_0to2min']\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        mean_percentage_change_train = y_train.mean()\n",
    "        y_baseline_pred_test = np.full(y_test.shape, mean_percentage_change_train)\n",
    "\n",
    "        mse_baseline_test = mean_squared_error(y_test, y_baseline_pred_test)\n",
    "        r2_baseline_test = r2_score(y_test, y_baseline_pred_test)\n",
    "\n",
    "        ridge_model = Ridge(alpha=1.0)\n",
    "        ridge_model.fit(X_train, y_train)\n",
    "        y_pred_test_ridge = ridge_model.predict(X_test)\n",
    "        mse_ridge_test = mean_squared_error(y_test, y_pred_test_ridge)\n",
    "        r2_ridge_test = r2_score(y_test, y_pred_test_ridge)\n",
    "\n",
    "        coefficients = pd.DataFrame({'Feature': ['Intercept'] + list(X.columns),\n",
    "                                     'Coefficient': [ridge_model.intercept_] + list(ridge_model.coef_)})\n",
    "\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.scatter(y_test, y_pred_test_ridge, alpha=0.7, label='Ridge Predictions')\n",
    "        plt.scatter(y_test, y_baseline_pred_test, alpha=0.7, marker='x', color='green', label='Baseline Predictions (Mean)')\n",
    "        plt.plot(y_test, y_test, color='red', linestyle='--', linewidth=1, label='Perfect Prediction')\n",
    "        plt.xlabel('Actual Percentage Change (Test Set)')\n",
    "        plt.ylabel('Predicted Percentage Change (Test Set)')\n",
    "        plt.title('Ridge vs. Baseline (Mean) Prediction: Actual vs Predicted Price Change')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        predictions_plot = plt\n",
    "        predictions_plot.savefig('plots/prediction_plot_ridge_reg.png')\n",
    "\n",
    "        return ridge_model, mse_ridge_test, r2_ridge_test, coefficients, predictions_plot, mse_baseline_test, r2_baseline_test\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during Ridge regression fitting: {e}\")\n",
    "        return None, None, None, None, None, None, None\n",
    "\n",
    "ridge_model, mse_ridge, r2_ridge, coefficients_df, prediction_plot_ridge_reg, mse_baseline, r2_baseline = ridge_regression_for_price_change(date_percentage_change_df_sorted.copy())\n",
    "\n",
    "print(\"\\n--- Model Comparison Results ---\")\n",
    "print(\"\\nRidge Regression Model:\")\n",
    "print(f\"  Test Mean Squared Error: {mse_ridge:.4f}\")\n",
    "print(f\"  Test R-squared: {r2_ridge:.4f}\")\n",
    "\n",
    "print(\"\\nBaseline Model (Mean Prediction):\")\n",
    "print(f\"  Test Mean Squared Error: {mse_baseline:.4f}\")\n",
    "print(f\"  Test R-squared: {r2_baseline:.4f}\")\n",
    "\n",
    "print(\"\\nPrediction Plot:\")\n",
    "prediction_plot_ridge_reg.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7320847",
   "metadata": {},
   "source": [
    "### Research Question 1. How might one characterize the effect that the EIA WPSR release have on the Crude Oil Futures Market? Is it statistically significant and over what time interval is this effect the strongest?\n",
    "\n",
    "Our first research question sought to understand how the EIA WPSR release affects the Crude Oil Futures Market, specifically addressing its statistical significance and the duration of its strongest impact.  We definitively conclude that the WPSR release has a significant impact on the market, supported by two key findings:\n",
    "\n",
    "**Finding #1: Trading Volume Dynamics Around WPSR Release**\n",
    "\n",
    "We observed a distinct pattern in trading volume in the minutes surrounding the WPSR release. As illustrated \n",
    "\n",
    "<iframe src=\"plots/fig_volume_scatter_release.html\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe> \n",
    "\n",
    "trading volume steadily decreases in the approximately 30 minutes leading up to the release.  However, precisely at the moment of the WPSR release, there is a sharp and substantial jump in trading volume.\n",
    "\n",
    "\n",
    "This behavior suggests that traders become hesitant to engage in trading activity as the report release approaches, anticipating potential price volatility. Upon the report's release, the market rapidly absorbs the information, leading to a surge in trading activity as participants react to the news and attempt to capitalize on the anticipated price adjustments. This volume spike is a clear indicator of the WPSR's immediate market impact.\n",
    "\n",
    "**Finding #2: Statistically Significant Change in Minute-to-Minute Price Behavior Post-Release**\n",
    "\n",
    "Beyond volume, we examined the minute-to-minute price behavior before and after WPSR releases to look for any statistically significant changes.\n",
    "\n",
    "<iframe src=\"plots/fig_heatmap_release.html\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe> \n",
    "\n",
    "<iframe src=\"plots/fig_heatmap_non_release.html\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe> \n",
    "As seen in the two heatmaps, it's pretty apparent that price fluctuations are noticeably more frequent and potentially larger in magnitude immediately following a WPSR release compared to days without a release.\n",
    "\n",
    "To quantify this observation, we conducted a two-sample Kolmogorov-Smirnov (KS) test on the distributions of minute-to-minute price changes after WPSR releases, comparing them to \"normal\" price change distributions (days without releases).\n",
    "\n",
    "<img src=\"plots/line_plot_p_vaue_KS_test.png\" alt=\"ks_test line plot failed to load\"> \n",
    "\n",
    "As seen in the line plot, the p-value remains below our chosen significance threshold of 0.1 for the first three minutes after the report release.  This indicates that the price change distributions in these minutes are statistically significantly different from normal price behavior.\n",
    "\n",
    "The p-value rising above 0.1 after the third minute suggests that the market, on average, takes around 2 minutes to fully absorb the information from the WPSR and revert to its typical trading patterns.\n",
    "\n",
    "\n",
    "### Research Question 2. Among the new market-relevant information found in the the EIA WPSR, what portion/s of the data is most relevant to the traders, and thus most relevant to the \"irregular\" price behavior?\n",
    "\n",
    "Building upon the evidence of the WPSR's market impact from Research Question 1, our second research question aimed to discern which specific data components within the WPSR are most important to traders and contribute most to the \"irregular\" price behavior.  We initially hypothesized that traders primarily interpret WPSR information through the lens of basic supply and demand principles.  Our core assumption was that market reactions would stem from perceived supply-demand imbalances signaled by the WPSR, with excess supply leading to price decreases and excess demand driving price increases.\n",
    "\n",
    "We came up with two main interpretations of how traders might utilize WPSR data to assess these imbalances:\n",
    "\n",
    "**Interpretation #1: Reaction to Raw Week-to-Week Crude Oil Supply Changes**\n",
    "\n",
    "This interpretation essentially implies that traders focus on the direct week-over-week change in domestic crude oil supply as reported by the EIA. Under this view, market price reactions should have a pretty linear correlation with corresponding supply changes.\n",
    "\n",
    "**Interpretation #2: Reaction to Supply Surprise - Deviation from Expectations**\n",
    "\n",
    "The second interpretation goes even further and assumes that traders consider the \"supply surprise\" as the key driver of market reactions. This \"surprise\" is defined as the difference between the EIA's reported supply change and pre-release supply change predictions from third-party sources (such as Investing.com or the American Petroleum Institute - API). This perspective assumes that the price already reflects some running consensus expectation of the supply change prior to the WPSR release. Then once the WPSR releases, it acts as a correction mechanism, with the market reacting primarily to the deviation from these pre-existing expectations.\n",
    "\n",
    "To investigate these interpretations, we explored the relationship between supply-demand imbalances (as defined by both interpretations) and subsequent price movements through visual inspection.  \n",
    "\n",
    "\n",
    "<iframe src=\"plots/fig_scatter_surprise_vs_pricechange_EIA.html\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe> \n",
    "\n",
    "<iframe src=\"plots/fig_scatter_surprise_vs_pricechange_Investingcom.html\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe> \n",
    "\n",
    "<iframe src=\"plots/fig_scatter_surprise_vs_pricechange_api.html\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe> \n",
    "\n",
    "Our analysis revealed that the relationships between these hypothesized supply-demand imbalance metrics and price movements are considerably obscured by noise. Even after coloring dots based on how recent the event was, the expected linear correlation was still not very strongly evident in the data.  While visually inspecting the scatter plots, we observed slightly less noise associated with Interpretation #1 (raw supply change) compared to Interpretation #2 (supply surprise). Thus, we decided to go with Interpretation #1 for further analysis, acknowledging the inherent noise and potential non-linearity in the relationship.\n",
    "\n",
    "### Research Question 3. Given the noise and possible non-linearity found in the relationship between the WPSR supply change information and the crude oil futures price movement, how can we use machine learning techniques to model this relationship and predict the price behavior based on the information found in the WPSR?\n",
    "\n",
    "Given the observed noise and the possibility of non-linear relationships between WPSR supply change information and crude oil futures price movements, our third research question is geared towards exploring the possiblity that machine learning techniques can be used to model and potentially predict price behavior based on WPSR data.\n",
    "\n",
    "We compared a total of 5 different machine learning models against a baseline of using the mean. These models included:\n",
    "\n",
    "*   **Kernel Regression (Gaussian Kernel)**\n",
    "\n",
    "<img src=\"plots/kernel_reg_plot.png\" alt=\"kernel regression plot failed to load\"> \n",
    "\n",
    "*   **LOESS Regression** (Locally Estimated Scatterplot Smoothing)\n",
    "\n",
    "<img src=\"plots/loess.png\" alt=\"kernel regression plot failed to load\"> \n",
    "\n",
    "*   **Random Forest Regression**\n",
    "\n",
    "<img src=\"plots/rf_feature_fig.png\" alt=\"random forest feature importance plot failed to load\"> \n",
    "\n",
    "<img src=\"plots/rf_actual_pred_fig.png\" alt=\"random forest prediction plot failed to load\"> \n",
    "\n",
    "*   **Random Forest Regression with Gradient Boosting (XGBoost)**\n",
    "\n",
    "<img src=\"plots/xgb_feature_fig.png\" alt=\"random forest feature importance plot failed to load\"> \n",
    "\n",
    "<img src=\"plots/xgb_actual_pred_fig.png\" alt=\"random forest prediction plot failed to load\"> \n",
    "\n",
    "*   **Ridge Regression (Regularized Linear Regression) VS Baseline Mean** \n",
    "\n",
    "<img src=\"plots/prediction_plot_ridge_reg.png\" alt=\"ridge regression prediction plot failed to load\"> \n",
    "\n",
    "Unfortunately, despite testing these diverse models and tuning hyperparameters using GridSearchCV, we were unable to develop any models with significant predictive accuracy.  Our best performing model was a Random Forest Regressor, which achieved an R-squared value of only 0.0171 and a Mean Squared Error of 0.0290 on the test set.  The incredibly low R-squared value indicates that our model is barely better than the mean at predicting the price change accurately. Additionally, while the MSE seems low, it is still relatively high considering the scale of the price changes.\n",
    "\n",
    "\\begin{array}{|l|c|c|}\n",
    "\\hline\n",
    "\\textbf{Model} & \\textbf{MSE} & \\textbf{\\( R^2 \\)} \\\\\n",
    "\\hline\n",
    "\\textbf{Kernel Regression (Gaussian Kernel)} & 0.0258 & -0.0543 \\\\\n",
    "\\hline\n",
    "\\textbf{LOESS Regression (Locally Estimated Scatterplot Smoothing)} & 0.0317 & 0.0002 \\\\\n",
    "\\hline\n",
    "\\textbf{Random Forest Regression} & 0.0290 & 0.0171 \\\\\n",
    "\\hline\n",
    "\\textbf{Random Forest Regression with Gradient Boosting (XGBoost)} & 0.0294 & 0.0007 \\\\\n",
    "\\hline\n",
    "\\textbf{Ridge Regression (Regularized Linear Regression)} & 0.0294 & 0.0029 \\\\\n",
    "\\hline\n",
    "\\textbf{Baseline Mean} & 0.0295 & -0.0002 \\\\\n",
    "\\hline\n",
    "\\end{array}\n",
    "\n",
    "After careful consideration of the project's scope, the course context, and the limited success of our machine learning efforts, we conclude that the precise mechanisms driving the erratic price behavior following EIA WPSR releases likely involve complexities beyond our current understanding and analytical toolkit.  While our analysis confirms that the WPSR release significantly affects crude oil futures prices, the relationship between specific WPSR supply information and price movement appears to be far more intricate and less directly driven by simple supply and demand principles as presented in introductory microeconomics.  Further research employing more advanced econometric techniques, incorporating broader market factors, and potentially exploring higher-frequency data and more nuanced interpretations of market expectations could be necessary to develop more robust predictive models for WPSR-driven price behavior.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbb315b-34b2-4a19-8a67-7b8f96c24754",
   "metadata": {},
   "source": [
    "## Implications and Limitations\n",
    "\n",
    "# PLEASE NOTE THAT NONE OF THIS IS INVESTMENT ADVICE\n",
    "\n",
    "**Implications:**\n",
    "\n",
    "*   **Market Timing and Trading Strategies:** Our findings regarding the short-term market reaction (approximately 2-3 minutes) post-WPSR release could be of interest to high-frequency traders seeking to capitalize on the initial market response. However, given the low predictability indicated by our machine learning models, relying solely on WPSR data for profitable trading strategies is highly risky.\n",
    "*   **Understanding Market Efficiency:** The rapid market absorption of WPSR information (within minutes) suggests a relatively efficient market, at least in terms of incorporating publicly available information. However, the noise and low predictability also indicate that the market reaction is not entirely deterministic or easily modeled using simple supply and demand factors and basic machine learning.\n",
    "*   **EIA WPSR Report Significance:** Our project reinforces the importance of the EIA WPSR as a market-moving event. Even if the exact price reaction is hard to predict, the report undoubtedly triggers significant trading activity and short-term price volatility in the crude oil futures market.\n",
    "\n",
    "**Limitations:**\n",
    "\n",
    "1.  **Model Simplicity and Feature Engineering:** Our machine learning models were relatively basic and relied on a limited set of features (primarily supply change and prior price). More sophisticated models incorporating a wider range of market indicators (e.g., volatility, interest rates, global economic news, sentiment analysis), and more advanced feature engineering (e.g., lagged variables, technical indicators) might yield improved results.\n",
    "2.  **Data Noise and Non-Linearity:** The inherent noise in financial market data and the potential for non-linear and complex relationships between WPSR data and price movements pose a significant challenge. Simple linear models and even basic non-linear models may be insufficient to capture the underlying dynamics.\n",
    "3.  **Limited Scope of WPSR Data Interpretation:** Our project focused on two simplified interpretations of how traders might react to WPSR data. It is far more likely that market participants employ far more sophisticated and diverse strategies, considering multiple aspects of the WPSR report, incorporating proprietary information, and reacting to market sentiment and momentum in addition to fundamental supply-demand factors.\n",
    "4.  **Focus on Aggregate Supply Change:** We primarily focused on the aggregate crude oil supply change. The WPSR contains a wealth of other information (e.g., gasoline and distillate inventories, refinery utilization, production data). Investigating the market's reaction to these other components might reveal additional insights and potentially stronger predictive signals.\n",
    "5.  **Time Horizon:** Our analysis focused on the immediate (minute-to-minute and up to 2-minute) price reactions. The WPSR might have longer-term lagged impacts on crude oil prices that our short-term analysis did not capture.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
